---
title: "BINF690 homework solutions"
author: "Rafael Villasmil"
date: "12/13/2021"
output: word_document
---


Assignment 1
1.13 Suppose that a spherical droplet of liquid evaporates at a rate that is proportional to its surface area. dVdt=−kA where V=volume (mm3), t=time (min), k=the evaporation rate(mm/min), and A=surface area (mm2). Use Euler’s method to compute the volume of the droplet from t=0 to 10 min using a step size of 0.25 min. Assume that k=0.08 mm/min and that the droplet initially has a radius of 2.5 mm. Assess the validity of your results by determining the radius of your final computed volume and verifying that it is consistent with the evaporation rate. 

    Send me the plot V=V(t) and your code implementing Euler algorithm.
    Explain what will happen with the droplet at t>10 min.
    Obtain analytical solution and compare it with the numerical one.

Assignment (c) is optional, but I will give extra point if it is done correctly. 

```{r Assignment_1}
t0 <- 0
tf <- 10
step <- 0.25
k <- 0.08
r0 <- 2.5

x <- seq(t0,tf,by=step)



drop_data <- data.frame(x)
dependent_variables <- c("vol_euler","vol_analytical")
drop_data[,dependent_variables] <- NA
drop_data[1,dependent_variables] <- (4/3 * pi * r0^3)

for (i in 2:nrow(drop_data)){
  drop_data[i,"vol_euler"] <- (drop_data[1,"vol_euler"] - (k * drop_data[i,'x'] * 4 * pi * r0^2))  
  drop_data[i,"vol_analytical"] <- (4/3 * pi * (r0-(k*drop_data[i,'x']))^3)
}

plot(drop_data[,'x'],drop_data[,"vol_euler",], 
     main="Drop Evaporation", 
     ylab="",
     type="l",
     col="blue")
     lines(drop_data[,'x'],
           drop_data[,"vol_analytical"], col="red")
     legend("bottomleft",
     c("Euler","Analytical"),
     fill=c("blue","red"))

```

Assignment 2
1. Prove the expression for the error propagation for the function f(x,y)=x/y.
2. Solve problems 4.5 and 4.8 (5th edition) or 4.4 and 4.10 (6th edition) or 4.6 and 4.11 (7th edition)

```{r}

```


Assignment 3
Solve problems 5.12 and 6.4. 

```{r problem_5.12}
Ealimit <- 5
Ea <- 101

xi <- 0
xi_memory_1 <- NA
xi_memory_2 <- NA
xr_memory <- NA
xu <- 1

#should be updated accorging to problem
first_dev <- function(x) {
  y <- -12*x^5-6*x^3+10
  return(y)
}

while (Ea > Ealimit){
 
  yi <- first_dev(xi)
  yu <- first_dev(xu)
  
  yproduct <- yi*yu
  
  if (yproduct > 0) {
    xr_memory <- xr} 

  xr <- (xi+xu)/2
  
 if (yproduct < 0) {
    xr_memory <- xi
    xi <- xr
 } else {
    if (is.na(xi_memory_1)) {
      xu <- xr
      } else {
        xu <- xi
        xi <- xi_memory_2
          }
 }
  
  if (is.na(xi_memory_1)){
    xi_memory_1 <- 2*xr
    } else {
      xi_memory_2 <- xi_memory_1
      xi_memory_1 <- xi
    }
  
  Ea <- abs((xr_memory - xr) * 100/ xr)
 
}

print(xu)

```

```{r find_roots_newton_raphson_method}
# tip graph fuctions and start upwards after a maxima or minimum


# orignal_func and first derivative must be upstated according to problem

original_func <- function(x) {
  y <- -1+5.5*x-4*x^2+0.5*x^3
  return(y)
}

first_dev <- function(x) {
  y <- 5.5-8*x+1.5*x^2
  return(y)
}

# enter Es percentage as a percentage 
Es <- 0.01

Et <- 101
root_memory <- NA

xi<- 5

counter <- 0
while (Et > Es){
  counter <- counter + 1
#  print(c(counter,Et,root_memory))
  
  if (is.na(root_memory)) {root_memory <- xi}
  
  root <- root_memory - original_func(root_memory)/first_dev(root_memory)
  
  Et <- abs(100* (root_memory - root)/root)
  
  root_memory <- root
}

counter <- counter + 1
cat(c("Steps: ", counter, "Root: ", root))

```



Assignment 4
Solve problem 9.9
```{r solve_variables_multiple_equations}
# create matrix of equations 
eq1 <- c(8, 2, -2, -2)
eq2 <- c(10, 2, 4, 4)
eq3 <- c(12, 2, 2, 6)

original_matrix <- data.frame(eq1, eq2, eq3)

eq_matrix <- t(original_matrix)

# normalize equations to the one with lowest row
for (rowcheck in 1:(nrow(eq_matrix)-1)){
  denominator <- eq_matrix[rowcheck,rowcheck]
  for (i in rowcheck:(nrow(eq_matrix)-1)){
    for (j in 1:ncol(eq_matrix)){
      if (j==rowcheck) {numerator <- eq_matrix[(i+1),j]}
      eq_matrix[(i+1),j] <- (eq_matrix[(i+1),j] - ((numerator/denominator) * eq_matrix[rowcheck,j]))
    }
  }  
}

# solve for Xs

solutions <- matrix(NA, ncol=nrow(eq_matrix))

for (i in nrow(eq_matrix):2){
  xi <- (eq_matrix[i,ncol(eq_matrix)] - sum(eq_matrix[i,1:(i-1)])) / eq_matrix[i,i]
  solutions[1,i] <- xi
  for (j in i:1){
    eq_matrix[j,ncol(eq_matrix)] <- eq_matrix[j,ncol(eq_matrix)] - (xi *eq_matrix[j,i])
    eq_matrix[j,i] <- 0
  }
}

solutions[1,1] <- eq_matrix[1,ncol(eq_matrix)]/eq_matrix[1,1]



```


Assignment 5

    Using code solve problem 14.8. **For extra credit, write a code which performs multiple iterations of steepest descent method. 
    Prove the expression for the 2nd order derivative d2f/dxdy.


```{r}

# for the function f(x,y) = -8x+x^2+12y+4y^2-2xy
function_xy <- function(x,y) {
  z <- -8*x+x^2+12*y+4*y^2-2*x*y
  return(z)
}

first_der_x <- function(x) {
  y <- -8+2*x-2*y
  return(y)
}

firstder_y <- function(y) {
  x <- 12+8*y-2*x
  return(x)
}

```

Assignment
Assignment 6
1. Solve problem 17.7 (5th textbook edition) or 17.6 (6th or 7th editions).
 
```{r least_squares_regression_to_fit_a_straight_line}
x_values <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)
y_values <- c(1, 1.5, 2, 3, 4, 5, 8, 10, 13)

ls_table <- data.frame(x_values, y_values)
ls_table[,"x^2"] <- ls_table[,"x_values"]^2 
ls_table[,"xy"] <- ls_table[,"x_values"] * ls_table[,"y_values"]

n <- nrow(ls_table)

slope <- ((n*sum(ls_table[,"xy"])) - (sum(ls_table[,"x_values"])*sum(ls_table[,"y_values"])))/((n*sum(ls_table[,"x^2"]))-(sum(ls_table[,"x_values"])^2))

intercept <- (sum(ls_table[,"y_values"]) - (slope *sum(ls_table[,"x_values"]))) / n

ls_table[,"estimate_y"] <- slope* ls_table[,"x_values"] + intercept

plot(ls_table[,"x_values"], ls_table[,"y_values"])
lines(ls_table[,"x_values"], ls_table[,"estimate_y"] )

ls_table[,"yi-y_mean"] <- abs(ls_table[,"y_values"] - mean(ls_table[,"y_values"]))

Sy <- sqrt(sum(ls_table[,"yi-y_mean"])/(n-1))

Syx <- sqrt((sum((ls_table[,"y_values"] - ls_table[,"estimate_y"])^2))/(n-2))

if (Syx < Sy) {
  
  r2 <- sqrt((sum(ls_table[,"yi-y_mean"])-sum((ls_table[,"y_values"] - ls_table[,"estimate_y"])^2))/(sum(ls_table[,"yi-y_mean"])))
  
  cat("Syx < Sy, the linear regresion has merit.",
      (round(r2, 3)*100), "% of the original uncertainty has been explained by the linear model", "\n")
  cat("Least Square Regression:  y=", slope, "* x", intercept,"\n")
  
}


```

2. Use the data from problem 18.4 (5th edition) or 18.5 (6th or 7th editions) to predict the value of the function at x=2.8. Use fifth order interpolating polynomial. 

```{r first_order_polynomial-regresion}
# data 
x_values <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)
y_values <- c(1, 1.5, 2, 3, 4, 5, 8, 10, 13)

# number of data sets 
m <- 2
n <- length(x_values)
xmean <- mean(x_values) 
ymean <- mean(y_values)
xsum <- sum(x_values)
ysum <- sum(y_values)
xp2sum <- sum(x_values^2)
xp3sum <- sum(x_values^3)
xp4sum <- sum(x_values^4)
xysum <- sum(x_values*y_values)
xp2ysum <- sum(((x_values^2)*y_values))

# create matrix of equations 
eq1 <- c(n,     xsum,   xp2sum, ysum)
eq2 <- c(xsum,  xp2sum, xp3sum, xysum)
eq3 <- c(xp2sum,xp3sum, xp4sum, xp2ysum)

original_matrix <- data.frame(eq1, eq2, eq3)

eq_matrix <- t(original_matrix)

# normalize equations to the one with lowest row
for (rowcheck in 1:(nrow(eq_matrix)-1)){
  denominator <- eq_matrix[rowcheck,rowcheck]
  for (i in rowcheck:(nrow(eq_matrix)-1)){
    for (j in 1:ncol(eq_matrix)){
      if (j==rowcheck) {numerator <- eq_matrix[(i+1),j]}
      eq_matrix[(i+1),j] <- (eq_matrix[(i+1),j] - ((numerator/denominator) * eq_matrix[rowcheck,j]))
    }
  }  
}

# solve for Xs

solutions <- matrix(NA, ncol=nrow(eq_matrix))

for (i in nrow(eq_matrix):2){
  xi <- (eq_matrix[i,ncol(eq_matrix)] - sum(eq_matrix[i,1:(i-1)])) / eq_matrix[i,i]
  solutions[1,i] <- xi
  for (j in i:1){
    eq_matrix[j,ncol(eq_matrix)] <- eq_matrix[j,ncol(eq_matrix)] - (xi *eq_matrix[j,i])
    eq_matrix[j,i] <- 0
  }
}

solutions[1,1] <- eq_matrix[1,ncol(eq_matrix)]/eq_matrix[1,1]

yi_values <- NULL
for (i in 1:length(x_values)){
  for (j in 1:length(solutions)){
    if (j==1){newyi <-solutions[1]} 
      else{newyi <-newyi + solutions[j] * x_values[i]^(j-1)}
  }
  yi_values <- append(yi_values, newyi, length(yi_values))
}

yi_values

plot(x_values,y_values)
lines(x_values,y_values,type="l",col="red")
lines(x_values,yi_values,col="green")

sumyremainp2 <- sum((y_values-yi_values)^2)
sumyremainp2
```
```{r second_order_polynomial-regresion}
# data 
x_values <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)
y_values <- c(1, 1.5, 2, 3, 4, 5, 8, 10, 13)

# number of data sets 
m <- 2
n <- length(x_values)
xmean <- mean(x_values) 
ymean <- mean(y_values)
xsum <- sum(x_values)
ysum <- sum(y_values)
xp2sum <- sum(x_values^2)
xp3sum <- sum(x_values^3)
xp4sum <- sum(x_values^4)
xp5sum <- sum(x_values^5)
xp6sum <- sum(x_values^6)
xysum <- sum(x_values*y_values)
xp2ysum <- sum(((x_values^2)*y_values))
xp3ysum <- sum(((x_values^3)*y_values))

# create matrix of equations 
eq1 <- c(n,      xsum,   xp2sum, xp3sum, ysum)
eq2 <- c(xsum,   xp2sum, xp3sum, xp4sum, xysum)
eq3 <- c(xp2sum, xp3sum, xp4sum, xp5sum, xp2ysum)
eq4 <- c(xp3sum, xp4sum, xp5sum, xp6sum, xp3ysum)

original_matrix <- data.frame(eq1, eq2, eq3, eq4)

eq_matrix <- t(original_matrix)
  
# normalize equations to the one with lowest row
for (rowcheck in 1:(nrow(eq_matrix)-1)){
  denominator <- eq_matrix[rowcheck,rowcheck]
  for (i in rowcheck:(nrow(eq_matrix)-1)){
    for (j in 1:ncol(eq_matrix)){
      if (j==rowcheck) {numerator <- eq_matrix[(i+1),j]}
      eq_matrix[(i+1),j] <- (eq_matrix[(i+1),j] - ((numerator/denominator) * eq_matrix[rowcheck,j]))
    }
  }  
}

# solve for Xs

solutions <- matrix(NA, ncol=nrow(eq_matrix))

for (i in nrow(eq_matrix):2){
  xi <- (eq_matrix[i,ncol(eq_matrix)] - sum(eq_matrix[i,1:(i-1)])) / eq_matrix[i,i]
  solutions[1,i] <- xi
  for (j in i:1){
    eq_matrix[j,ncol(eq_matrix)] <- eq_matrix[j,ncol(eq_matrix)] - (xi *eq_matrix[j,i])
    eq_matrix[j,i] <- 0
  }
}

solutions[1,1] <- eq_matrix[1,ncol(eq_matrix)]/eq_matrix[1,1]

yi_values <- NULL
for (i in 1:length(x_values)){
  for (j in 1:length(solutions)){
    if (j==1){newyi <-solutions[1]} 
      else{newyi <-newyi + solutions[j] * x_values[i]^(j-1)}
  }
  yi_values <- append(yi_values, newyi, length(yi_values))
}

yi_values

plot(x_values,y_values)
lines(x_values,y_values,type="l",col="red")
lines(x_values,yi_values,col="green")

sumyremainp2 <- sum((y_values-yi_values)^2)
sumyremainp2
```


Midterm exam (BINF690)
1. Determine positive roots of the function f(x)=10cos(x)e-x/5–x1/3+1.8. Use (a)
graphical method; (b) Newton-Raphson method. All roots must be determined
with the absolute approximate error no larger than Ea = 10-6.

```{r find roots}
# question is only about positive roots
# becasue x^(1/3) is greatern than 10*cos(x)*exp(-1*x/5) +1.8 after 13.22, 
# series stops at 14
# steps of 0.05 provides good display for graph

#create x series for plot
x <- seq(from = 0, to = 14, by = 0.05)

#define function for ploting
original_func <- function(x){
  y <- 10*cos(x)*exp(-1*x/5)-x^(1/3)+1.8
  return(y)
}

#plot x data and y=0 line to indicate roots.
plot(x,original_func(x), xaxt = "n")
axis(1, at = seq(round(min(x)),
                 round(max(x)), by = 1))
abline(h=0,v=seq(round(min(x)),
                 round(max(x)), by = 1))

resolution <- 10^-6
roots <- NULL
for (i in seq(from = 0, to = 14, by = resolution)){
  if ((original_func(i) < resolution)&&(original_func(i)) > (-1 * resolution)){
    if (is.null(roots)) {
      roots <- i} 
      else {
        if (i>(roots[length(roots)]+2*resolution)){
          roots <- append(roots, i, after = length(roots))}
      }
  }
}

cat("Roots are ", roots)
```
```{r find_roots_newton_raphson_method}

# orignal_func and first derivative must be updated according to problem

original_func <- function(x){
  y <- 10*cos(x)*exp(-1*x/5)-x^(1/3)+1.8
  return(y)
}

first_dev <- function(x) {
  y <- -10*sin(x)*exp(-1*x/5)-2*cos(x)*exp(-1*x/5)-1/(3*x^(2/3))
  return(y)
}

# enter Es percentage as a percentage 
Es <- 0.01

Et <- 101
root_memory <- NA

xi<- 13

counter <- 0
while (Et > Es){
  counter <- counter + 1
#  print(c(counter,Et,root_memory))
  
  if (is.na(root_memory)) {root_memory <- xi}
  
  root <- root_memory - original_func(root_memory)/first_dev(root_memory)
  
  Et <- abs(100* (root_memory - root)/root)
  
  root_memory <- root
}

counter <- counter + 1
cat("Steps: ", counter, "Root: ", root, "\n")

```

2. Using Gaussian elimination with partial pivoting solve linear algebraic equations
x1 + x2 – x3 = -3
6x1 + 2x2 + 2x3 = 2
-3x1 + 4x2 + x3 = 1

Also, compute the value of determinant.
Both problems must be solved using computer codes. You must submit the codes with
your answers.

```{r solve_variables_multiple_equations}
# create matrix of equations 
eq1 <- c(1, 1, -1, -3)
eq2 <- c(6, 2, 2, 2)
eq3 <- c(-3, 4, 1, 1)

original_matrix <- t(data.frame(eq1, eq2, eq3))

eq_matrix <- original_matrix

# normalize equations to the one with lowest row
for (rowcheck in 1:(nrow(eq_matrix)-1)){
  denominator <- eq_matrix[rowcheck,rowcheck]
  for (i in rowcheck:(nrow(eq_matrix)-1)){
    for (j in 1:ncol(eq_matrix)){
      if (j==rowcheck) {numerator <- eq_matrix[(i+1),j]}
      eq_matrix[(i+1),j] <- (eq_matrix[(i+1),j] - ((numerator/denominator) * eq_matrix[rowcheck,j]))
    }
  }  
}

# solve for Xs

solutions <- matrix(NA, ncol=nrow(eq_matrix))

for (i in nrow(eq_matrix):2){
  xi <- (eq_matrix[i,ncol(eq_matrix)] - sum(eq_matrix[i,1:(i-1)])) / eq_matrix[i,i]
  solutions[1,i] <- xi
  for (j in i:1){
    eq_matrix[j,ncol(eq_matrix)] <- eq_matrix[j,ncol(eq_matrix)] - (xi *eq_matrix[j,i])
    eq_matrix[j,i] <- 0
  }
}

solutions[1,1] <- eq_matrix[1,ncol(eq_matrix)]/eq_matrix[1,1]
addition <- 0
for (i in 1:nrow(eq_matrix)){
  for (j in 1:ncol(solutions)){
    addition <- addition + (original_matrix[i,j]*solutions[1,j])
  }
  cat("Solution to equation ", i, " is ", addition, "\n")
  addition <- 0
}

```

```{r}

```

Assignment 7

    Solve problem 21.5. In addition, (a) compute integral using trapezoidal rule (n=5); (b) compute integral using Romberg integration (n1=5, n2=10); (c) compare numerical results with analytical integration.
    Compute the integral for the 3rd order interpolating polynomial from the derivation of 1/3 Simpson method done in the class. 
```{r}

```

Assignment 8
Solve problem 25.9 (5th edition) or 25.5 (6th or 7th editions). Please note that Heun (or predictor-corrector method) without corrector is an Euler method. 
In addition, (a) use predictor-corrector method; (b) use 4th order RK method to solve the problem; (c) plot all solutions. 

```{r Euler}
h <- 0.1
y0 <- 1
t0 <- 0
tf <- 3

# this function should be updated according to problem
function_8 <- function(y,t) {
  x <- y * sin(t)^3
  return(x)
}

euler_data <- data.frame(c(seq(t0,tf,by=h)))
colnames(euler_data) <- "time"
euler_data[,"Euler"] <- NA
euler_data[1,"Euler"] <- y0

for (i in 2:nrow(euler_data)){
  euler_data[i,"Euler"] <- euler_data[(i-1),"Euler"] + (h * function_8(euler_data[(i-1),"Euler"], euler_data[(i-1),"time"]))
}
```

```{r Heuns}
h <- 0.1
y0 <- 1
t0 <- 0
tf <- 3

# this function should be updated according to problem
function_8 <- function(y,t) {
  x <- y * sin(t)^3
  return(x)
}

heuns_data <- data.frame(c(seq(t0,tf,by=h)))
colnames(heuns_data) <- "time"
heuns_data[,"Euler"] <- NA
heuns_data[1,"Euler"] <- y0

for (i in 2:nrow(heuns_data)){
  heuns_data[i,"Euler"] <- heuns_data[(i-1),"Euler"] + (h * function_8(heuns_data[(i-1),"Euler"], heuns_data[(i-1),"time"]))
}

heuns_data[,"dy/dt"] <- NA
heuns_data[,"slope"] <- NA
heuns_data[,"Heuns"] <- NA
heuns_data[1,"dy/dt"] <- function_8(y0,t0)
heuns_data[1,"Heuns"] <- y0

for (i in 2:nrow(heuns_data)){
  
  heuns_data[i,"dy/dt"] <- heuns_data[i,"Euler"] * sin(heuns_data[i,"time"])^3
  
  heuns_data[i,"slope"] <- mean(c(heuns_data[(i-1),"dy/dt"],heuns_data[i,"dy/dt"]))
  
  heuns_data[i,"Heuns"] <- heuns_data[(i-1),"Heuns"] + heuns_data[i,"slope"] * h
}
```

```{r ralston_method}
h <- 0.1
y0 <- 1
t0 <- 0
tf <- 3

# this function should be updated according to problem
function_8 <- function(y,t) {
  x <- y * sin(t)^3
  return(x)
}

ralston_data <- data.frame(c(seq(t0,tf,by=h)))
colnames(ralston_data) <- "time"
ralston_data[,"Ralston"] <- NA
ralston_data[,"k1"] <- NA
ralston_data[,"k2"] <- NA
ralston_data[,"ksum"] <- NA
ralston_data[1,"Ralston"] <- y0


for (i in 1:(nrow(ralston_data)-1)){
  
  ralston_data[i,"k1"] <- function_8(ralston_data[i,"Ralston"], ralston_data[i,"time"])
  
  ralston_data[i,"k2"] <- function_8((ralston_data[i,"Ralston"] + (3/4 * ralston_data[i,"k1" ] * h)), (ralston_data[i,"time"]+3/4*h))
  
ralston_data[i,"ksum"] <- ((1/3 * ralston_data[i,"k1"]) + (2/3 * ralston_data[i,"k2"]))

  ralston_data[(i+1),"Ralston"] <- ralston_data[i,"Ralston"] + ralston_data[i,"ksum"] * h
}
```

```{r 4th_order_RK_method}
h <- 0.1
y0 <- 1
t0 <- 0
tf <- 3

# this function should be updated according to problem
function_8 <- function(y,t) {
  x <- y * sin(t)^3
  return(x)
}

rk_data <- data.frame(c(seq(t0,tf,by=h)))
colnames(rk_data) <- "time"
rk_data[,"RK"] <- NA
rk_data[,"k1"] <- NA
rk_data[,"k2"] <- NA
rk_data[,"k3"] <- NA
rk_data[,"k4"] <- NA
rk_data[,"ksum"] <- NA
rk_data[1,"RK"] <- y0


for (i in 1:(nrow(rk_data)-1)){
  
  rk_data[i,"k1"] <- function_8(rk_data[i,"RK"],rk_data[i,"time"])
  
  rk_data[i,"k2"] <- function_8((rk_data[i,"RK"]+1/2*rk_data[i,"k1"]* h),(rk_data[i,"time"]+1/2 * h))
  
  rk_data[i,"k3"] <- function_8((rk_data[i,"RK"]+1/2*rk_data[i,"k2"] * h),(rk_data[i,"time"] + 1/2 * h))
  
  rk_data[i,"k4"] <- function_8((rk_data[i,"RK"] + rk_data[i,"k3"] * h),(rk_data[i,"time"] + h))
  
  rk_data[i,"ksum"] <- rk_data[i,"k1"] + 2 * rk_data[i,"k2"] + 2 * rk_data[i,"k3"] + rk_data[i,"k4"]
  
  rk_data[(i+1),"RK"] <- rk_data[i,"RK"] + (1/6 * rk_data[i,"ksum"] * h)
  
}  

```

```{r mid_point}
h <- 0.1
y0 <- 1
t0 <- 0
tf <- 3

# this function should be updated according to problem
function_8 <- function(y,t) {
  x <- y * sin(t)^3
  return(x)
}

mp_data <- data.frame(c(seq(t0,tf,by=h)))
colnames(mp_data) <- "time"
mp_data[,"Euler"] <- NA
mp_data[1,"Euler"] <- y0

for (i in 2:nrow(mp_data)){
  mp_data[i,"Euler"] <- mp_data[(i-1),"Euler"] + (h * function_8(mp_data[(i-1),"Euler"], mp_data[(i-1),"time"]))
}

mp_data[,"dy/dt"] <- function_8(mp_data[,"Euler"], mp_data[,"time"])

mp_data[,"yi+1/2"] <- NA
mp_data[,"MidPoint_Dy/dt"] <- NA
mp_data[,"Mid_Point"] <- NA
mp_data[1,"Mid_Point"] <- y0

for (i in 1:(nrow(mp_data)-1)){
  mp_data[i,"yi+1/2"] <- mp_data[i,"Mid_Point"] + (1/2 * mp_data[i,"dy/dt"] * h)
  mp_data[i,"MidPoint_Dy/dt"] <- function_8(mp_data[i,"yi+1/2"],(mp_data[i,"time"] + 1/2 * h))
  mp_data[(i+1),"Mid_Point"] <- mp_data[i,"Mid_Point"] + (mp_data[i,"MidPoint_Dy/dt"] * h)
}
```


Assignment 9
Solve problems 27.11 and 27.12. 
```{r}


```

Assignment 10
Find two errors in section IV of Lecture notes (NumericalMethodsMD.pdf). 
```{r}

```

Assignment 11
Homework on Monte Carlo algorithm
Consider a single atom, which has the potential energy E(x)=kc*x^2, where x is atom’s
coordinate and kc=0.1 is a constant. Develop a Monte Carlo (MC) program, which
computes the average energy <E> of this atom at the temperatures T from 0.1 to 1.0 with
the increment of 0.1. For simplicity assume that kB=1. Set maximum position
displacement during MC move to dx=10. Also, set at each temperature the initial
coordinate value x to 100.
If MC code works correctly, then <E> ≈ T/2. The deviation of <E> from the theoretical
result T/2 should not exceed 10%. Present the results as a plot <E> vs T and as a table.
Include in the table the number of MC steps performed to obtain <E> at each T. I also
need to see your code.
Optional assignment for extra credit: Compute the acceptance rate at each temperature
and investigate its dependence on temperature.

```{r monte_carlo_Average_energy}

# data input
kc <- 0.1
kB <- 1
dx <- 10
x0 <- 100
t0 <- 0.1
tf <- 1
dt <- 0.1

# derived constants for this code

# matrix for data storage
col_names <- c("Temperature", "Expected_Ea", "Calculated_Ea", "Iterations", "Accepted_Iterations", "Acceptance_Rate")
Temperature <- c(seq(t0, tf, by = dt))

results <- as.data.frame(matrix(NA, nrow = length(Temperature), ncol = length(col_names)))

colnames(results) <- col_names

results[,Temperature] <- Temperature
results[,"Expected_Ea"] <- results[,"Temperature"]/2


for (i in 1:nrow(results)){
  
  temp <- results[i,"Temperature"]
  
  # while loop preamble 
  Energy_limit <- (1+dx/100)*temp/2
  Energy_average <- 2 * Energy_limit
  Ei_sum <- 0
  counter_iterations <- 0
  counter_accepted <-0
  x <- x0
  possible_steps <- c(seq(from = (-1*dx), to = dx))
  
  while (Energy_average > Energy_limit){
    counter_iterations <- counter_iterations + 1
    energy0 <- kc * x^2
    x1 <- x + sample(possible_steps, 1)
    energy1 <- kc * (x1)^2
    rel_bolxtman <- exp(-(energy1-energy0)/(kB*temp))
    if (rel_bolxtman > runif(1)) {
      x <- x1
      counter_accepted <- counter_accepted + 1 }
    Ei_sum <- Ei_sum + energy0
    Energy_average <- Ei_sum / counter_iterations
  }
  
  results[i,"Calculated_Ea"] <- Energy_average
  results[i,"Iterations"] <- counter_iterations
  results[i,"Accepted_Iterations"] <- counter_accepted
  
}
results[,"Acceptance_Rate"] <- results[,"Accepted_Iterations"] / results[,"Iterations"]

plot(results[,"Temperature"], results[,"Acceptance_Rate"])

```

Final exam (2020 BINF690)
1. Consider the data points
x 1 2 3 5 7 8
f(x) 3 6 19 99 291 444
Using these data calculate f(x=4) applying the interpolating polynomials of the 1st
through 4th orders, i.e., in all consider four interpolations. Will the 5th order
interpolation improve the prediction of f(x=4)?

```{r general_interpolating_polynomials}

# enter and organize data
x_values <-  c(1, 2, 3, 5, 7, 8)
fx_values <- c(3, 6, 19, 99, 291, 444)

original_matrix <- data.frame(x_values, fx_values)
i<-1
j<-1

# calculate finite divided differences

for (i in 1:((nrow(original_matrix)-1))){
  original_matrix <- cbind(original_matrix, NA)
  names(original_matrix)[names(original_matrix) == "NA"] <- i
  for (j in 1:((table(is.na(original_matrix[,as.character(i)]))-1))){
    colgrep <- grep(as.character(i), colnames(original_matrix))
    original_matrix[j,colgrep] <- 
      (original_matrix[(j+1),(colgrep-1)] - original_matrix[j,(colgrep-1)])/
      (original_matrix[colgrep,"x_values"] - original_matrix[(colgrep-1),"x_values"])
  }
}
```


2. Problem 21.15. Before solving this problem study the example 21.9 in the
textbook; to obtain analytical solution, first integrate over x from -3 to 1, then
over y from 0 to 2, and finally over z from -2 to 2. Compute relative true error
using the difference between analytical and numerical solutions.

3. Solve the differential equation from t=0 to t=3 using Euler and 4th order Runge-
Kutta methods2
ty
dt
dy −=
, y(0)=0
Use the integration step of 0.2. Compute the approximate error at t=3 as a
difference between two numerical solutions.

4. Using Euler method solve the system of differential equations





=
−=
y
dt
dx
x
dt
dy 

5.0 Apply the following initial conditions: x(t=0)=0 and1)0( ==ty . Set the
integration step to t=0.1. What are the values of x(t=10) and y(t=10)?
Include the codes used to solve the problems. Answers should be highlighted.

```{r}

```

